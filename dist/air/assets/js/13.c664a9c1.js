(window.webpackJsonp=window.webpackJsonp||[]).push([[13],{218:function(e,r,t){"use strict";t.r(r);var n=t(0),a=Object(n.a)({},function(){var e=this,r=e.$createElement,t=e._self._c||r;return t("div",{staticClass:"content"},[t("p",[e._v("我之前写过一篇机器学习的入门文章，因为我也是在入门和在学习的人，所以，那篇文章和这篇机器学习和人工智能方向的文章可能都会有点太肤浅。如果你有更好的学习方式或资料，欢迎补充。")]),e._v(" "),e._m(0),e._v(" "),t("p",[e._v("我们先来介绍一下机器学习的基本原理。")]),e._v(" "),t("p",[e._v("机器学习主要有两种方式，一种是监督式学习（Supervised Learning），另一种是非监督式学习（Unsupervised Learning）。下面简单地说一下这两者的不同。")]),e._v(" "),e._m(1),e._v(" "),t("p",[e._v("我们这么来说吧，监督式学习是在被告诉过了正确的答案后的学习，而非监督式学习是在没有被告诉正确答案时的学习。所以，非监督式学习是在大量的非常乱的数据中找寻一些潜在的关系，这个成本也比较高。非监督式学习经常被用来检测一些不正常的事情发生，比如信用卡的诈骗或是盗刷。也被用在推荐系统，比如买了这个商品的人又买了别的什么商品，或是如果某个人喜欢某篇文章、某个音乐、某个餐馆，那么他可能会喜欢某个车、某个明星或某个地方。")]),e._v(" "),t("p",[e._v('在监督式学习算法下，我们可以用一组"狗"的照片来确定某个照片中的物体是不是狗。而在非监督式学习算法下，我们可以通过一个照片来找到其中有与其相似的事物的照片。这两种学习方式都有些有用的场景。')]),e._v(" "),t("p",[e._v("关于机器学习，你可以读一读 "),t("a",{attrs:{href:"https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471",target:"_blank",rel:"noopener noreferrer"}},[e._v("Machine Learning is Fun!"),t("OutboundLink")],1),e._v(" ，这篇文章（"),t("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/24339995",target:"_blank",rel:"noopener noreferrer"}},[e._v("中文翻译版"),t("OutboundLink")],1),e._v("）恐怕是全世界最简单的入门资料了。")]),e._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"https://becominghuman.ai/data-science-simplified-principles-and-process-b06304d63308",target:"_blank",rel:"noopener noreferrer"}},[e._v("Data Science Simplified Part 1: Principles and Process"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://towardsdatascience.com/data-science-simplified-key-concepts-of-statistical-learning-45648049709e",target:"_blank",rel:"noopener noreferrer"}},[e._v("Data Science Simplified Part 2: Key Concepts of Statistical Learning"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://towardsdatascience.com/data-science-simplified-hypothesis-testing-56e180ef2f71",target:"_blank",rel:"noopener noreferrer"}},[e._v("Data Science Simplified Part 3: Hypothesis Testing"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://towardsdatascience.com/data-science-simplified-simple-linear-regression-models-3a97811a6a3d",target:"_blank",rel:"noopener noreferrer"}},[e._v("Data Science Simplified Part 4: Simple Linear Regression Models"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://towardsdatascience.com/data-science-simplified-part-5-multivariate-regression-models-7684b0489015",target:"_blank",rel:"noopener noreferrer"}},[e._v("Data Science Simplified Part 5: Multivariate Regression Models"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://towardsdatascience.com/data-science-simplified-part-6-model-selection-methods-2511cbdf7cb0",target:"_blank",rel:"noopener noreferrer"}},[e._v("Data Science Simplified Part 6: Model Selection Methods"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://towardsdatascience.com/data-science-simplified-part-7-log-log-regression-models-499ecd1495f0",target:"_blank",rel:"noopener noreferrer"}},[e._v("Data Science Simplified Part 7: Log-Log Regression Models"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://towardsdatascience.com/data-science-simplified-part-8-qualitative-variables-in-regression-models-d1817d56245c",target:"_blank",rel:"noopener noreferrer"}},[e._v("Data Science Simplified Part 8: Qualitative Variables in Regression Models"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://towardsdatascience.com/data-science-simplified-part-9-interactions-and-limitations-of-regression-models-4702dff03820",target:"_blank",rel:"noopener noreferrer"}},[e._v("Data Science Simplified Part 9: Interactions and Limitations of Regression Models"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://towardsdatascience.com/data-science-simplified-part-10-an-introduction-to-classification-models-82490f6c171f",target:"_blank",rel:"noopener noreferrer"}},[e._v("Data Science Simplified Part 10: An Introduction to Classification Models"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://towardsdatascience.com/data-science-simplified-part-11-logistic-regression-5ae8d994bf0e",target:"_blank",rel:"noopener noreferrer"}},[e._v("Data Science Simplified Part 11: Logistic Regression"),t("OutboundLink")],1)])]),e._v(" "),e._m(2),e._v(" "),t("p",[e._v("接下来，我们需要比较专业地学习一下机器学习了。")]),e._v(" "),t("p",[e._v("在学习机器学习之前，我们需要学习数据分析，所以，我们得先学一些大数据相关的东西，也就是Data Science相关的内容。下面是两个不错的和数据科学相关的教程以及一个资源列表。")]),e._v(" "),t("ul",[t("li",[t("p",[t("a",{attrs:{href:"http://data8.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("UC Berkeley’s Data 8: The Foundations of Data Science"),t("OutboundLink")],1),e._v(" 和电子书 "),t("a",{attrs:{href:"https://www.inferentialthinking.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Computational and Inferential Thinking"),t("OutboundLink")],1),e._v(" 会讲述数据科学方面非常关键的概念，会教会你在数据中找到数据的关联、预测和相关的推断。")])]),e._v(" "),t("li",[t("p",[t("a",{attrs:{href:"https://github.com/nborwankar/LearnDataScience",target:"_blank",rel:"noopener noreferrer"}},[e._v("Learn Data Science"),t("OutboundLink")],1),e._v(" ，这是GitHub上的一本电子书，主要是一些数据挖掘的算法，比如线性回归、逻辑回归、随机森林、K-Means聚类的数据分析。然后，"),t("a",{attrs:{href:"https://github.com/donnemartin/data-science-ipython-notebooks#scikit-learn",target:"_blank",rel:"noopener noreferrer"}},[e._v("donnemartin/data-science-ipython-notebooks"),t("OutboundLink")],1),e._v(" 这个代码仓库中用TensorFlow、scikit-learn、Pandas、NumPy、Spark等把这些经典的例子实现了个遍。")])]),e._v(" "),t("li",[t("p",[t("a",{attrs:{href:"https://www.datascienceweekly.org/data-science-resources/the-big-list-of-data-science-resources",target:"_blank",rel:"noopener noreferrer"}},[e._v("Data Science Resources List"),t("OutboundLink")],1),e._v(" ，这个网站上有一个非常长的和数据科学相关的资源列表，你可以从中得到很多你想要的东西。")])])]),e._v(" "),t("p",[e._v("之后，有下面几门不错的在线机器学习的课程供你入门，也是非常不错。")]),e._v(" "),t("ul",[t("li",[t("p",[e._v("吴恩达教授（Andrew Ng）在 "),t("a",{attrs:{href:"https://www.coursera.org/learn/machine-learning",target:"_blank",rel:"noopener noreferrer"}},[e._v("Coursera 上的免费机器学习课程"),t("OutboundLink")],1),e._v(" 非常棒。我强烈建议从此入手。对于任何拥有计算机或科学学位的人，或是还能记住一点点数学知识的人来说，都应该非常容易入门。这个斯坦福大学的课程请尽量拿满分。可以在 "),t("a",{attrs:{href:"http://open.163.com/special/opencourse/machinelearning.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("网易公开课"),t("OutboundLink")],1),e._v(" 中找到这一课程。除此之外，吴恩达教授还有一组新的和深度学习相关的课程，现在可以在网易公开课上免费学习——"),t("a",{attrs:{href:"https://mooc.study.163.com/smartSpec/detail/1001319001.htm",target:"_blank",rel:"noopener noreferrer"}},[e._v("Deep Learning Specialization"),t("OutboundLink")],1),e._v("。")])]),e._v(" "),t("li",[t("p",[t("a",{attrs:{href:"https://www.udacity.com/course/deep-learning--ud730",target:"_blank",rel:"noopener noreferrer"}},[e._v("Deep Learning by Google"),t("OutboundLink")],1),e._v(" ，Google的一个关于深度学习的在线免费课程，其支持中英文。这门课会教授你如何训练和优化基本神经网络、卷积神经网络和长短期记忆网络。你将通过项目和任务接触完整的机器学习系统TensorFlow。")])]),e._v(" "),t("li",[t("p",[e._v("卡内基梅隆大学汤姆·米切尔（Tom Mitchell）的机器学习 "),t("a",{attrs:{href:"http://www.cs.cmu.edu/%7Etom/10701_sp11/lectures.shtml",target:"_blank",rel:"noopener noreferrer"}},[e._v("英文原版视频与课件PDF"),t("OutboundLink")],1),e._v(" 。")])]),e._v(" "),t("li",[t("p",[e._v("2013年加利福尼亚理工学院亚瑟·阿布-穆斯塔法（Yaser Abu-Mostafa）的Learning from Data "),t("a",{attrs:{href:"http://work.caltech.edu/lectures.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("课程视频及课件PDF"),t("OutboundLink")],1),e._v("，内容更适合进阶。")])]),e._v(" "),t("li",[t("p",[e._v("关于神经网络方面，YouTube上有一个非常火的课程视频，由宾夕法尼亚大学的雨果·拉罗歇尔（Hugo Larochelle）的教学课程 - "),t("a",{attrs:{href:"https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH",target:"_blank",rel:"noopener noreferrer"}},[e._v("Neural networks class - Université de Sherbrooke"),t("OutboundLink")],1),e._v(" 。")])])]),e._v(" "),t("p",[e._v("除此之外，还有很多的在线大学课程你可以学习。比如：")]),e._v(" "),t("ul",[t("li",[t("p",[e._v("斯坦福大学的《"),t("a",{attrs:{href:"https://lagunita.stanford.edu/courses/HumanitiesandScience/StatLearning/Winter2015/about",target:"_blank",rel:"noopener noreferrer"}},[e._v("统计学学习"),t("OutboundLink")],1),e._v("》、《"),t("a",{attrs:{href:"http://cs229.stanford.edu/",target:"_blank",rel:"noopener noreferrer"}},[e._v("机器学习"),t("OutboundLink")],1),e._v("》、《"),t("a",{attrs:{href:"http://cs231n.stanford.edu/",target:"_blank",rel:"noopener noreferrer"}},[e._v("卷积神经网络"),t("OutboundLink")],1),e._v("》、《"),t("a",{attrs:{href:"http://cs224d.stanford.edu/",target:"_blank",rel:"noopener noreferrer"}},[e._v("深度学习之自然语言处理"),t("OutboundLink")],1),e._v("》等。")])]),e._v(" "),t("li",[t("p",[e._v("麻省理工大学的《"),t("a",{attrs:{href:"http://ocw.mit.edu/courses/brain-and-cognitive-sciences/9-641j-introduction-to-neural-networks-spring-2005/index.htm",target:"_blank",rel:"noopener noreferrer"}},[e._v("神经网络介绍"),t("OutboundLink")],1),e._v(" 》、《"),t("a",{attrs:{href:"http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-867-machine-learning-fall-2006/",target:"_blank",rel:"noopener noreferrer"}},[e._v("机器学习"),t("OutboundLink")],1),e._v("》、《"),t("a",{attrs:{href:"http://ocw.mit.edu/courses/sloan-school-of-management/15-097-prediction-machine-learning-and-statistics-spring-2012/index.htm",target:"_blank",rel:"noopener noreferrer"}},[e._v("预测"),t("OutboundLink")],1),e._v("》等。")])])]),e._v(" "),t("p",[e._v("更多的列表，请参看——"),t("a",{attrs:{href:"https://github.com/RatulGhosh/awesome-machine-learning",target:"_blank",rel:"noopener noreferrer"}},[e._v("Awesome Machine Learning Courses"),t("OutboundLink")],1),e._v("。")]),e._v(" "),e._m(3),e._v(" "),t("ul",[t("li",[t("p",[e._v("《"),t("a",{attrs:{href:"https://book.douban.com/subject/2061116/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Pattern Recognition and Machine Learning"),t("OutboundLink")],1),e._v("》，这本书是机器学习领域的圣经之作。该书也是众多高校机器学习研究生课程的教科书，Google上有"),t("a",{attrs:{href:"http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("PDF版的下载"),t("OutboundLink")],1),e._v("。这本书很经典，但并不适合入门来看。GitHub上有这本中的 "),t("a",{attrs:{href:"https://github.com/PRML/PRMLT",target:"_blank",rel:"noopener noreferrer"}},[e._v("Matlab 实现"),t("OutboundLink")],1),e._v("。")])]),e._v(" "),t("li",[t("p",[e._v("下面这两本电子书也是比较经典的，其中讲了很多机器学习的知识，可以当做手册或字典。")]),e._v(" "),t("ul",[t("li",[e._v("《"),t("a",{attrs:{href:"https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Understanding Machine Learning: From Theory to Algorithms"),t("OutboundLink")],1),e._v("》。")]),e._v(" "),t("li",[e._v("《"),t("a",{attrs:{href:"https://web.stanford.edu/~hastie/Papers/ESLII.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("The Elements of Statistical Learning - Second Edition"),t("OutboundLink")],1),e._v("》。")])])]),e._v(" "),t("li",[t("p",[e._v("《"),t("a",{attrs:{href:"https://book.douban.com/subject/27087503/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Deep Learning: Adaptive Computation and Machine Learning series"),t("OutboundLink")],1),e._v('》 中文翻译为《深度学习》，又叫"花书"。这本书由全球知名的三位专家伊恩·古德费洛（Ian Goodfellow）、友华·本吉奥（Yoshua Bengio）和亚伦·考维尔（Aaron Courville）撰写，是深度学习领域奠基性的经典教材。')]),e._v(" "),t("p",[e._v("全书内容包括3部分：第1部分介绍基本的数学工具和机器学习的概念，它们是深度学习的预备知识；第2部分系统深入地讲解现今已成熟的深度学习方法和技术；第3部分讨论某些具有前瞻性的方向和想法，它们被公认为是深度学习未来的研究重点。这本书的官网为 “"),t("a",{attrs:{href:"http://www.deeplearningbook.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("deeplearningbook.org"),t("OutboundLink")],1),e._v("”，在GitHub上也有中文翻译 - 《"),t("a",{attrs:{href:"https://github.com/exacity/deeplearningbook-chinese",target:"_blank",rel:"noopener noreferrer"}},[e._v("Deep Learning 中文翻译"),t("OutboundLink")],1),e._v("》。")])]),e._v(" "),t("li",[t("p",[e._v("《"),t("a",{attrs:{href:"http://neuralnetworksanddeeplearning.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Neural Networks and Deep Learning"),t("OutboundLink")],1),e._v("》（"),t("a",{attrs:{href:"https://tigerneil.gitbooks.io/neural-networks-and-deep-learning-zh/content/",target:"_blank",rel:"noopener noreferrer"}},[e._v("中文翻译版"),t("OutboundLink")],1),e._v("），这是一本非常不错的神经网络的入门书，在"),t("a",{attrs:{href:"https://book.douban.com/subject/26727997/",target:"_blank",rel:"noopener noreferrer"}},[e._v("豆瓣上评分9.5分"),t("OutboundLink")],1),e._v("，从理论讲到了代码。虽然有很多数学公式，但是有代码相助，就不难理解了。其中讲了很多如激活函数、代价函数、随机梯度下降、反向传播、过度拟合和规范化、权重初始化、超参数优化、卷积网络的局部感受野、混合层、特征映射的东西。")])]),e._v(" "),t("li",[t("p",[e._v("《"),t("a",{attrs:{href:"https://book.douban.com/subject/26279609/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Introduction to Machine Learning with Python"),t("OutboundLink")],1),e._v("》，算是本不错的入门书，也是本比较易读的英文书。其是以Scikit-Learn框架来讲述的。如果你用过Scikit这个框架，那么你学这本书还是很不错的。")])]),e._v(" "),t("li",[t("p",[e._v("《"),t("a",{attrs:{href:"https://book.douban.com/subject/26840215/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Hands-On Machine Learning with Scikit-Learn and TensorFlow"),t("OutboundLink")],1),e._v(" 》，这是一门以TensorFlow为工具的入门书，其用丰富的例子从实站的角度来让你学习。这本书对于无基础的人也是适合的，对于小白来说虽然略难但是受益匪浅。")])])]),e._v(" "),e._m(4),e._v(" "),t("p",[e._v("除了上述的那些课程和图书外，下面这些文章也很不错。")]),e._v(" "),t("ul",[t("li",[t("p",[e._v("YouTube 上的 Google Developers 的 "),t("a",{attrs:{href:"https://www.youtube.com/playlist?list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal",target:"_blank",rel:"noopener noreferrer"}},[e._v("Machine Learning Recipes with Josh Gordon"),t("OutboundLink")],1),e._v(" ，这9集视频，每集不到10分钟，从Hello World讲到如何使用TensorFlow，非常值得一看。")])]),e._v(" "),t("li",[t("p",[e._v("还有 "),t("a",{attrs:{href:"https://pythonprogramming.net/machine-learning-tutorial-python-introduction/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Practical Machine Learning Tutorial with Python Introduction"),t("OutboundLink")],1),e._v(" 上面一系列的用Python带着你玩Machine Learning的教程。")])]),e._v(" "),t("li",[t("p",[e._v("Medium上的 "),t("a",{attrs:{href:"https://medium.com/machine-learning-101",target:"_blank",rel:"noopener noreferrer"}},[e._v("Machine Learning - 101"),t("OutboundLink")],1),e._v(" ，讲述了好些我们上面提到过的经典算法。")])]),e._v(" "),t("li",[t("p",[e._v("Medium上的 "),t("a",{attrs:{href:"https://medium.com/machine-learning-for-humans",target:"_blank",rel:"noopener noreferrer"}},[e._v("Marchine Learning for Humans"),t("OutboundLink")],1),e._v("。")])]),e._v(" "),t("li",[t("p",[t("a",{attrs:{href:"https://machinelearningmastery.com/blog/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Dr. Jason Brownlee 的博客"),t("OutboundLink")],1),e._v(" ，也非常值得一读，其中好多的 “How-To”，会让你有很多的收获。")])]),e._v(" "),t("li",[t("p",[t("a",{attrs:{href:"http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Rules of Machine Learning: Best Practices for ML Engineering"),t("OutboundLink")],1),e._v(" ，一些机器学习相关的最佳实践。")])]),e._v(" "),t("li",[t("p",[t("a",{attrs:{href:"http://iamtrask.github.io",target:"_blank",rel:"noopener noreferrer"}},[e._v("i am trask"),t("OutboundLink")],1),e._v(" ，也是一个很不错的博客。")])]),e._v(" "),t("li",[t("p",[e._v("关于Deep Learning中的神经网络，YouTube上有介绍视频 "),t("a",{attrs:{href:"https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi",target:"_blank",rel:"noopener noreferrer"}},[e._v("Neural Networks"),t("OutboundLink")],1),e._v("。")])]),e._v(" "),t("li",[t("p",[e._v("麻省理工学院的电子书 "),t("a",{attrs:{href:"http://www.deeplearningbook.org",target:"_blank",rel:"noopener noreferrer"}},[e._v("Deep Learning"),t("OutboundLink")],1),e._v("。")])]),e._v(" "),t("li",[t("p",[e._v("用Python做自然语言处理"),t("a",{attrs:{href:"http://www.nltk.org/book/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Natural Language Processing with Python"),t("OutboundLink")],1),e._v("。")])]),e._v(" "),t("li",[t("p",[e._v("最后一个是Machine Learning和Deep Learning的相关教程列表，"),t("a",{attrs:{href:"https://github.com/ujjwalkarn/Machine-Learning-Tutorials",target:"_blank",rel:"noopener noreferrer"}},[e._v("Machine Learning & Deep Learning Tutorials"),t("OutboundLink")],1),e._v("。")])])]),e._v(" "),t("p",[e._v("下面是一些和神经网络相关的不错的文章。")]),e._v(" "),t("ul",[t("li",[t("p",[t("a",{attrs:{href:"http://karpathy.github.io/2015/05/21/rnn-effectiveness/",target:"_blank",rel:"noopener noreferrer"}},[e._v("The Unreasonable Effectiveness of Recurrent Neural Networks"),t("OutboundLink")],1),e._v(" ，这是一篇必读的文章 ，告诉你为什么要学RNN，以及展示了最简单的NLP形式。")])]),e._v(" "),t("li",[t("p",[t("a",{attrs:{href:"http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Neural Networks, Manifolds, and Topology"),t("OutboundLink")],1),e._v(" ，这篇文章可以帮助你理解神经网络的一些概念。")])]),e._v(" "),t("li",[t("p",[t("a",{attrs:{href:"http://colah.github.io/posts/2015-08-Understanding-LSTMs/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Understanding LSTM Networks"),t("OutboundLink")],1),e._v(" ，解释了什么是LSTM的内在工作原理。")])]),e._v(" "),t("li",[t("p",[t("a",{attrs:{href:"http://distill.pub/2016/augmented-rnns/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Attention and Augmented Recurrent Neural Networks"),t("OutboundLink")],1),e._v(" ，用了好多图来说明了RNN的attention机制。")])]),e._v(" "),t("li",[t("p",[t("a",{attrs:{href:"http://benanne.github.io/2014/08/05/spotify-cnns.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Recommending music on Spotify with deep learning"),t("OutboundLink")],1),e._v(" ，一个在Spotify的实习生分享的音乐聚类的文章。")])])]),e._v(" "),e._m(5),e._v(" "),t("p",[e._v("下面是10个非常经典的机器学习的算法。")]),e._v(" "),t("ul",[t("li",[t("p",[e._v("对于监督式学习，有如下经典算法。")]),e._v(" "),t("ol",[t("li",[t("p",[t("a",{attrs:{href:"https://en.wikipedia.org/wiki/Decision_tree",target:"_blank",rel:"noopener noreferrer"}},[e._v("决策树（Decision Tree）"),t("OutboundLink")],1),e._v("，比如自动化放贷、风控。")])]),e._v(" "),t("li",[t("p",[t("a",{attrs:{href:"https://en.wikipedia.org/wiki/Naive_Bayes_classifier",target:"_blank",rel:"noopener noreferrer"}},[e._v("朴素贝叶斯分类器（Naive Bayesian classifier)"),t("OutboundLink")],1),e._v("，可以用于判断垃圾邮件、对新闻的类别进行分类，比如科技、政治、运动、判断文本表达的感情是积极的还是消极的、人脸识别等。")])]),e._v(" "),t("li",[t("p",[t("a",{attrs:{href:"https://en.wikipedia.org/wiki/Ordinary_least_squares",target:"_blank",rel:"noopener noreferrer"}},[e._v("最小二乘法（Ordinary Least Squares Regression）"),t("OutboundLink")],1),e._v("，是一种线性回归。")])]),e._v(" "),t("li",[t("p",[t("a",{attrs:{href:"https://en.wikipedia.org/wiki/Logistic_regression",target:"_blank",rel:"noopener noreferrer"}},[e._v("逻辑回归（Logisitic Regression）"),t("OutboundLink")],1),e._v("，一种强大的统计学方法，可以用一个或多个变量来表示一个二项式结果。可以用于信用评分，计算营销活动的成功率，预测某个产品的收入。")])]),e._v(" "),t("li",[t("p",[t("a",{attrs:{href:"https://en.wikipedia.org/wiki/Support_vector_machine",target:"_blank",rel:"noopener noreferrer"}},[e._v("支持向量机（Support Vector Machine，SVM）"),t("OutboundLink")],1),e._v("，可以用于基于图像的性别检测、图像分类等。")])]),e._v(" "),t("li",[t("p",[t("a",{attrs:{href:"https://en.wikipedia.org/wiki/Ensemble_learning",target:"_blank",rel:"noopener noreferrer"}},[e._v("集成方法（Ensemble methods）"),t("OutboundLink")],1),e._v("，通过构建一组分类器，然后通过它们的预测结果进行加权投票来对新的数据点进行分类。原始的集成方法是贝叶斯平均，但最近的算法包括纠错输出编码、Bagging和Boosting。")])])])]),e._v(" "),t("li",[t("p",[e._v("对于无监督式的学习，有如下经典算法。")]),e._v(" "),t("ol",[t("li",[t("p",[t("a",{attrs:{href:"https://en.wikipedia.org/wiki/Cluster_analysis",target:"_blank",rel:"noopener noreferrer"}},[e._v("聚类算法（Clustering Algorithms）"),t("OutboundLink")],1),e._v("。聚类算法有很多，目标是给数据分类。有5个比较著名的聚类算法你必需要知道："),t("a",{attrs:{href:"https://en.wikipedia.org/wiki/K-means_clustering",target:"_blank",rel:"noopener noreferrer"}},[e._v("K-Means"),t("OutboundLink")],1),e._v("、"),t("a",{attrs:{href:"https://en.wikipedia.org/wiki/Mean_shift",target:"_blank",rel:"noopener noreferrer"}},[e._v("Mean-Shift"),t("OutboundLink")],1),e._v("、"),t("a",{attrs:{href:"https://en.wikipedia.org/wiki/DBSCAN",target:"_blank",rel:"noopener noreferrer"}},[e._v("DBSCAN"),t("OutboundLink")],1),e._v("、"),t("a",{attrs:{href:"https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm",target:"_blank",rel:"noopener noreferrer"}},[e._v("EM/GMM"),t("OutboundLink")],1),e._v("、和 "),t("a",{attrs:{href:"https://en.wikipedia.org/wiki/Hierarchical_clustering",target:"_blank",rel:"noopener noreferrer"}},[e._v("Agglomerative Hierarchical"),t("OutboundLink")],1),e._v("。")])]),e._v(" "),t("li",[t("p",[t("a",{attrs:{href:"https://en.wikipedia.org/wiki/Principal_component_analysis",target:"_blank",rel:"noopener noreferrer"}},[e._v("主成分分析（Principal Component Analysis，PCA）"),t("OutboundLink")],1),e._v("。PCA的一些应用包括压缩、简化数据便于学习、可视化等。")])]),e._v(" "),t("li",[t("p",[t("a",{attrs:{href:"https://en.wikipedia.org/wiki/Singular-value_decomposition",target:"_blank",rel:"noopener noreferrer"}},[e._v("奇异值分解（Singular Value Decomposition，SVD）"),t("OutboundLink")],1),e._v('。实际上，PCA是SVD的一个简单应用。在计算机视觉中，第一个人脸识别算法使用PCA和SVD来将面部表示为"特征面"的线性组合，进行降维，然后通过简单的方法将面部匹配到身份。虽然现代方法更复杂，但很多方面仍然依赖于类似的技术。')])]),e._v(" "),t("li",[t("p",[t("a",{attrs:{href:"https://en.wikipedia.org/wiki/Independent_component_analysis",target:"_blank",rel:"noopener noreferrer"}},[e._v("独立成分分析（Independent Component Analysis，ICA）"),t("OutboundLink")],1),e._v("。ICA是一种统计技术，主要用于揭示随机变量、测量值或信号集中的隐藏因素。")])])])])]),e._v(" "),t("p",[e._v("如果你想了解更全的机器学习的算法列表，你可以看一下Wikipedia上的 "),t("a",{attrs:{href:"https://en.wikipedia.org/wiki/Outline_of_machine_learning#Machine_learning_algorithms",target:"_blank",rel:"noopener noreferrer"}},[e._v("List of Machine Learning Algorithms"),t("OutboundLink")],1),e._v("。")]),e._v(" "),t("p",[e._v("在 "),t("a",{attrs:{href:"https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/",target:"_blank",rel:"noopener noreferrer"}},[e._v("A Tour of Machine Learning Algorithms"),t("OutboundLink")],1),e._v(' ，这篇文章带你概览了一些机器学习算法，其中还有一个"脑图"可以下载，并还有一些How-To的文章供你参考。')]),e._v(" "),t("p",[e._v("对于这些算法，"),t("a",{attrs:{href:"http://scikit-learn.org/stable/",target:"_blank",rel:"noopener noreferrer"}},[e._v("SciKit-Learn"),t("OutboundLink")],1),e._v("有一些文档供你学习。")]),e._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"http://scikit-learn.org/stable/supervised_learning.html#supervised-learning",target:"_blank",rel:"noopener noreferrer"}},[e._v("1. Supervised learning"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"http://scikit-learn.org/stable/modules/clustering.html#clustering",target:"_blank",rel:"noopener noreferrer"}},[e._v("2.3 Clustering"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"http://scikit-learn.org/stable/modules/decomposition.html#decompositions",target:"_blank",rel:"noopener noreferrer"}},[e._v("2.5. Decomposing signals in components (matrix factorization problems)"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"http://scikit-learn.org/stable/model_selection.html#model-selection",target:"_blank",rel:"noopener noreferrer"}},[e._v("3. Model selection and evaluation"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing",target:"_blank",rel:"noopener noreferrer"}},[e._v("4.3. Preprocessing data"),t("OutboundLink")],1)])]),e._v(" "),e._m(6),e._v(" "),t("ul",[t("li",[t("p",[e._v('对于初学者来说，动手是非常非常重要的，不然，你会在理论的知识里迷失掉自己，这里有篇文章"'),t("a",{attrs:{href:"https://elitedatascience.com/machine-learning-projects-for-beginners",target:"_blank",rel:"noopener noreferrer"}},[e._v("8 Fun Machine Learning Projects for Beginners"),t("OutboundLink")],1),e._v('"，其中为初学者准备了8个很有趣的项目，你可以跟着练练。')])]),e._v(" "),t("li",[t("p",[e._v("学习机器学习或是人工智能你需要数据，这里有一个非常足的列表给你足够多的公共数据 – 《"),t("a",{attrs:{href:"https://github.com/awesomedata/awesome-public-datasets",target:"_blank",rel:"noopener noreferrer"}},[e._v("Awesome Public Datasets"),t("OutboundLink")],1),e._v("》，其中包括农业、生物、天气、计算机网络、地球科学、经济、教育、金融、能源、政府、健康、自然语言、体育等。")])]),e._v(" "),t("li",[t("p",[e._v("GitHub上的一些Awesome资源列表。")]),e._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"https://github.com/ChristosChristofidis/awesome-deep-learning",target:"_blank",rel:"noopener noreferrer"}},[e._v("Awesome Deep Learning"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://github.com/terryum/awesome-deep-learning-papers",target:"_blank",rel:"noopener noreferrer"}},[e._v("Awesome - Most Cited Deep Learning Papers"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://github.com/endymecy/awesome-deeplearning-resources",target:"_blank",rel:"noopener noreferrer"}},[e._v("Awesome Deep learning papers and other resources"),t("OutboundLink")],1)])])])]),e._v(" "),e._m(7),e._v(" "),t("p",[e._v("总结一下今天的内容。我首先介绍了机器学习的基本原理：监督式学习和非监督式学习，然后给出了全世界最简单的入门资料 "),t("a",{attrs:{href:"https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471",target:"_blank",rel:"noopener noreferrer"}},[e._v("Machine Learning is Fun!"),t("OutboundLink")],1),e._v("。随后给出了与机器学习密切相关的数据分析方面的内容和资料，然后推荐了深入学习机器学习知识的在线课程、图书和文章等，尤其列举了神经网络方面的学习资料。最后描述了机器学习的十大经典算法及相关的学习资料。")]),e._v(" "),t("p",[e._v("在机器学习和人工智能领域，我也在学习，也处于入门阶段，所以本文中推荐的内容，可能在你看来会有些浅。如果你有更好的信息和资料，欢迎补充。目前文章中给出来的是，我在学习过程中认为很不错的内容，我从中受益良多，所以希望它们也能为你的学习提供帮助。")]),e._v(" "),t("p",[e._v("从下篇文章开始，我们将进入前端知识的学习，包括基础和底层原理、性能优化、前端框架、UI/UX设计等内容。敬请期待。")]),e._v(" "),t("p",[e._v("下面是《程序员练级攻略（2018）》系列文章的目录。")]),e._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/8136",target:"_blank",rel:"noopener noreferrer"}},[e._v("开篇词"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("入门篇\n"),t("ul",[t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/8216",target:"_blank",rel:"noopener noreferrer"}},[e._v("零基础启蒙"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/8217",target:"_blank",rel:"noopener noreferrer"}},[e._v("正式入门"),t("OutboundLink")],1)])])]),e._v(" "),t("li",[e._v("修养篇\n"),t("ul",[t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/8700",target:"_blank",rel:"noopener noreferrer"}},[e._v("程序员修养"),t("OutboundLink")],1)])])]),e._v(" "),t("li",[e._v("专业基础篇\n"),t("ul",[t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/8701",target:"_blank",rel:"noopener noreferrer"}},[e._v("编程语言"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/8887",target:"_blank",rel:"noopener noreferrer"}},[e._v("理论学科"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/8888",target:"_blank",rel:"noopener noreferrer"}},[e._v("系统知识"),t("OutboundLink")],1)])])]),e._v(" "),t("li",[e._v("软件设计篇\n"),t("ul",[t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/9369",target:"_blank",rel:"noopener noreferrer"}},[e._v("软件设计"),t("OutboundLink")],1)])])]),e._v(" "),t("li",[e._v("高手成长篇\n"),t("ul",[t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/9759",target:"_blank",rel:"noopener noreferrer"}},[e._v("Linux系统、内存和网络（系统底层知识）"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/9851",target:"_blank",rel:"noopener noreferrer"}},[e._v("异步I/O模型和Lock-Free编程（系统底层知识）"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/10216",target:"_blank",rel:"noopener noreferrer"}},[e._v("Java底层知识"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/10301",target:"_blank",rel:"noopener noreferrer"}},[e._v("数据库"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/10603",target:"_blank",rel:"noopener noreferrer"}},[e._v("分布式架构入门（分布式架构）"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/10604",target:"_blank",rel:"noopener noreferrer"}},[e._v("分布式架构经典图书和论文（分布式架构）"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/11232",target:"_blank",rel:"noopener noreferrer"}},[e._v("分布式架构工程设计(分布式架构)"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/11116",target:"_blank",rel:"noopener noreferrer"}},[e._v("微服务"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/11665",target:"_blank",rel:"noopener noreferrer"}},[e._v("容器化和自动化运维"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/11669",target:"_blank",rel:"noopener noreferrer"}},[e._v("机器学习和人工智能"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/12271",target:"_blank",rel:"noopener noreferrer"}},[e._v("前端基础和底层原理（前端方向）"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/12389",target:"_blank",rel:"noopener noreferrer"}},[e._v("前端性能优化和框架（前端方向）"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/12486",target:"_blank",rel:"noopener noreferrer"}},[e._v("UI/UX设计（前端方向）"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://time.geekbang.org/column/article/12561",target:"_blank",rel:"noopener noreferrer"}},[e._v("技术资源集散地"),t("OutboundLink")],1)])])])]),e._v(" "),e._m(8)])},[function(){var e=this.$createElement,r=this._self._c||e;return r("h1",{attrs:{id:"基本原理简介"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#基本原理简介","aria-hidden":"true"}},[this._v("#")]),this._v(" 基本原理简介")])},function(){var e=this,r=e.$createElement,t=e._self._c||r;return t("ul",[t("li",[t("p",[t("strong",[e._v("监督式学习（Supervised Learning）")]),e._v("。所谓监督式学习，也就是说，我们需要提供一组学习样本，包括相关的特征数据和相应的标签。我们的程序可以通过这组样本来学习相关的规律或是模式，然后通过得到的规律或模式来判断没有被打过标签的数据是什么样的数据。")]),e._v(" "),t("p",[e._v("举个例子，假设需要识别一些手写的数字，我们要找到尽可能多的手写体的数字的图像样本，然后人工或是通过某种算法来明确地标注上什么是这些手写体的图片，谁是1，谁是2，谁是3…… 这组数据叫样本数据，又叫训练数据（training data）。然后通过机器学习的算法，找到每个数字在不同手写体下的特征，找到规律和模式。通过得到的规律或模式来识别那些没有被打过标签的手写数据，以此完成识别手写体数字的目的。")])]),e._v(" "),t("li",[t("p",[t("strong",[e._v("非监督式学习（Unsupervised Learning）")]),e._v('。对于非监督式学习，也就是说，数据是没有被标注过的，所以相关的机器学习算法需要找到这些数据中的共性。因为大量的数据是没被被标识过的，所以这种学习方式可以让大量的未标识的数据能够更有价值。而且，非监督式学习，可以为我们找到人类很难发现的数据里的规律或模型，所以也有人称这种学习为"特征点学习"，其可以让我们自动地为数据进行分类，并找到分类的模型。')]),e._v(" "),t("p",[e._v("一般来说，非监督式学习会应用在一些交易型的数据中。比如，你有一堆堆的用户购买数据，但是对于人类来说，我们很难找到用户属性和购买商品类型之间的关系。所以，非监督式学习算法可以帮助我们找到它们之间的关系。比如，一个在某个年龄段的女性购买了某种肥皂，有可能说明这个女性在怀孕期，或是某人购买儿童用品，有可能说明这个人的关系链中有孩子，等等。于是，这些信息会被用作一些所谓的精准市场营销活动，从而可以增加商品销量。")])])])},function(){var e=this.$createElement,r=this._self._c||e;return r("h1",{attrs:{id:"相关课程"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#相关课程","aria-hidden":"true"}},[this._v("#")]),this._v(" 相关课程")])},function(){var e=this.$createElement,r=this._self._c||e;return r("h1",{attrs:{id:"相关图书"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#相关图书","aria-hidden":"true"}},[this._v("#")]),this._v(" 相关图书")])},function(){var e=this.$createElement,r=this._self._c||e;return r("h1",{attrs:{id:"相关文章"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#相关文章","aria-hidden":"true"}},[this._v("#")]),this._v(" 相关文章")])},function(){var e=this.$createElement,r=this._self._c||e;return r("h1",{attrs:{id:"相关算法"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#相关算法","aria-hidden":"true"}},[this._v("#")]),this._v(" 相关算法")])},function(){var e=this.$createElement,r=this._self._c||e;return r("h1",{attrs:{id:"相关资源"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#相关资源","aria-hidden":"true"}},[this._v("#")]),this._v(" 相关资源")])},function(){var e=this.$createElement,r=this._self._c||e;return r("h1",{attrs:{id:"小结"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#小结","aria-hidden":"true"}},[this._v("#")]),this._v(" 小结")])},function(){var e=this.$createElement,r=this._self._c||e;return r("p",[r("img",{attrs:{src:"https://static001.geekbang.org/resource/image/fc/e9/fcc761001867c60f526665e237f831e9.jpg",alt:""}})])}],!1,null,null,null);r.default=a.exports}}]);